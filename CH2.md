#CH2 Intelligent Agents

##Agents and Environments

###Agent
Anything that:

* perceiving its **environment** through **sensors**
* acting upon that environment through **acuators**

###Percept
The agent's perceptual inputs at any given instant.

###Perspect sequence
The complete history of **everything** the agent has ever perceived.

###Dependence on percept
An agent's choice of action at any given instant can depend on the entire percept sequence observed to date, but **not** on anything it hasn't perceived.

###How to specify the agent's behavior
* Specify the agent's choice of action for every possible percept sequence
* Described by the **agent function** that maps any given percept sequence to action

###Agent function and agent program
* The agent function for an AI is **implemented** by an agent program
* The agent function is an **abstract methematical description**
* The agent program is a concrete implementation, running within some physical system

##Good Behavior: The Concept of Rationality

###Rational agent
For **each possible percept sequence**, a rational agent select an action that is expected to **maximize its performance measure**, given the evidence provided by the percept sequence and whatever built-in knowledge the agent has.

####Performance measure
Evaluates any given sequence of **environment states** and determine if the chosen sequence of actions is **desirable**.

It's **environment states**, not **agent states** -- you can't define your own success.

####Design principle of performance measure
It's better to design permorance according to **what one really wants** in the environment, rather than according to how one thinks the agent **should behave**.

###Rationality
Four factors:

* The **performance measure** that defines the criterion of success
* The agent's **prior knowledge** of the environment
* The **actions** that the agent can perform
* The agent's **percept sequence** to date

###Omnisience
* Knowing the **actual outcome** of its actions and can  act accordingly.
* Impossible -- you can't see the future.
* Rationality != perfection -- Raionality maximize the **expected outcome**, perfection maximize the **actual outcome**
* Rationality depends on the percept sequence **to date**

####Information gathering
* Doing actions in order to modify future percepts e.g. **exploration**
* R.A. gathers information

###Learning
* R.A. learns as much as possible from what it perceives

####a priori
Extreme cases: the environment is completely known

###Autonomy
* The more an agent **relies on the prior knowledge** of its designer rather than its own percepts, the more the agent **lacks autonomy**
* R.A. is autonomous: it learns what it can to compensate for **partial or incorrect** prior knowledge
* After sufficient experience of its environment, the behavior of a R.A can become effectively **independent of its prior knowledge**

##The Nature of environments
###Task environment
Essentially the problems to which rational agents are the solutions.

###Specifying the task environment: PEAS
####Performance measure
What is desired?
####Environment
What will the agent face?
####Acutuators
How can the agent act?
####Sensors
How can the agent perceive?

####Real environment v.s. artificial environment
**Real** or not is not important. What matters is:

* The complexity of the relationship among the **behavior** of the agent
* The **percept sequence** generated by the environment
* The **performance measure**

###Properties of task environments
####Fully observable v.s. partially observable
* Can I see the complete state of the environment?
* **Fully observable** 
	* The sensors can detect **all aspects** that are relevant to the choice of action
	* The agent **need not maintain any internal state** to keep track of the world -- it can be observed

####Single agent v.s. multiagent
* What can be viewed as agents
	* Can B's behavior best described as **maximizing a performance measure** whose value **depends on A's behavoir**?
* Categories
	* Competitive multiagent environment
	* Cooperative multiagent environment
* **Communications** as rational behavior
* **Randomized** behavior might be rational

####Deterministic v.s. stochastic
* Do I need to worry about uncertainty?
* Can the environment be **completely determined** by the current state and the action executed by the agent?
	* actions of other agent doesn't count
* **uncertain**: not fully observable || not dterministic
* **stochastic**
	* uncertain
	* outcomes quantified **with probabilities**
* **nonedterministic**
	* characterized by **possible outcomes**
	* uncertain **without probabilities**
	* performance measure would require the agent to success for **all possible outcomes**

####Episodic v.s. sequential

####Static v.s. dynamic

####Discrete v.s. continuous

####Known v.s. unknown



##The Structure of agents

###Agent programs

###Simple reflex agents

###Model-based reflex agents

###Goal-based agents

###Utility-based agents

###Learing agents

###How the components of agent programs work